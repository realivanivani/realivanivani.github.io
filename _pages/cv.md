---
layout: archive
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

I was born and raised in Novi Sad, Serbia, but as soon as I got scholarships I went abroad to study.

Education
======

![image](https://github.com/user-attachments/assets/6578c945-19c0-44f8-bf01-62a5aa710568){: .align-right width="200"}  
My academic journey took me to Prague, where I studied physics at Charles University after receiving a scholarship. I earned my MSc degree in Biophysics there, working on Raman spectroscopy of biomolecules. During my time in Prague, I became fluent in Czech, adding to my native Serbian. Later, I moved to Barcelona to pursue a PhD in Structural Biology under Professor Modesto Orozco. This period was crucial for my development as a scientist, and I was fortunate to contribute to some exciting research. This period was crucial for my development as a scientist, and I was fortunate to contribute to some exciting research. While in Barcelona, I also became fluent in Spanish.

## Researcher in Computational Biology in Prof. Orozco's Lab, Barcelona, Spain
![DNA surrounded with proteins](/images/dna_surrounded_proteins.jfif){: .align-right width="200"}
My scientific career began in computational biology, where I specialized in force-field parameterization and molecular dynamics simulations of DNA, RNA, and proteins. At the Orozco Lab in Barcelona, I generated and analyzed petabytes of simulation data, applying tools to analyze and extract high-resolution metadata from complex molecular systems. This work contributed to structural biology and pharmaceutical design, culminating in publications such as one  in *Nature Methods* (see my Publications tab!). I also collaborated with Dr. Eric Kool’s group at Stanford, gaining industry exposure and applying my research to real-world drug discovery pipelines. Full list of all my [scientific publications](https://scholar.google.com/citations?user=GqCZ-0QAAAAJ&hl=en)

Work experience
======

## Analytics Engineer Consultant in HTEC
![Red Guacamaya Consulting](/images/parrot_consulting_data_chatgpt.png){: .align-right width="200"}
Most recently, I joined the Tech Excellence Office at HTEC as a Data Analyst Lead, focusing on advanced data solutions for global enterprise clients such as Apple, Zuux, ASML, and Marlin. My role centers on translating strategic business goals into performant data architectures. I design and implement end-to-end analytical ecosystems using a modern stack—Databricks for unified compute and ML workflows, dbt for modular transformation logic and lineage visibility, DuckDB for high-speed local analytics, and Airflow to orchestrate complex dependencies at scale. In streaming environments, I leverage Kafka and Flink to build near real-time ingestion and enrichment layers, supporting low-latency decision systems. As part of the Tech Excellence group, I act as both a solutions architect and a lead analyst: auditing existing client infrastructure, benchmarking performance, and identifying opportunities to improve reliability, observability, and cost efficiency. I frequently prototype analytical frameworks, define data contracts, and guide teams through best practices in versioned pipelines, CI/CD, and governance.

## Data Manager & Analyst in International Committee of the Red Cross, Geneva/Amman/Damascus/Jerusalem/Caracas
![Red Guacamaya on red cross aid boxes](/images/parrot_on_redcross_boxes.jfif){: .align-right width="200"}
After my scientific career, my path took a different turn.  Working for the ICRC as a Data Analyst and Data Manager Lead in the Protection unit was an incredible experience.  I wasn't always crunching numbers in the office, but diving deep into data from around the world both remotely and on-site in places like Geneva, Syria, Palestine, and Venezuela. As part of the Protection Unit, I was responsible for the secure processing and management of sensitive personal data, ensuring compliance with privacy regulations and internal standards across multiple geographies. I built and maintained multi-location ETL pipelines using Python and SQL, improving data reliability and operational efficiency under challenging field conditions. My role bridged operational needs with technical execution—integrating field-level insights, designing scalable data workflows, and enforcing data governance for effective humanitarian action.

## Data Scientist in RnD unit of Continental, Serbia
![A parrot working on a computer with robotic arm](/images/parrot_comp_robot2.jfif){: .align-right width="200"}
I work in Continental’s R&D UX unit, where we manufacture in-car infotainment systems. My job combines data extraction and analysis, pipeline design, and data engineering, along with machine learning modeling to improve our products. I build robust data pipelines that process petabytes of manufacturing, enabling real-time insights and data-driven decision-making across international manufacturing ecosystem. I work with Manufacturing Execution System (MES) data on AWS and Oracle, covering different R&D areas and teams like Mechanical Engineering, Optical, and Display Technologies. I manage data access and analytical workflows across multiple global locations, ensuring consistency, scalability, and security. Using Power BI, I turn complex data into clear insights for engineers, leadership, and customers. I also develop Computer Vision algorithms to improve early-stage defect detection in manufacturing, always looking for new ways to use data for better decision-making.

My passion for computational science continues to inform my approach to data architecture, reproducibility, and system scalability in both industry and humanitarian sectors.



Skills
======
![image](https://github.com/user-attachments/assets/97f9a168-b4fb-4ebb-b3b1-f97f501714d0){: .align-right width="200"}  
Over the years, I’ve developed a robust toolbox tailored to cross-domain data challenges. My expertise includes:  
- **Data Science & Analytics**: Python (pandas, scikit-learn, NumPy, statsmodels), SQL (MS SQL, Posgresql), PySpark, and advanced statistical modeling.  
- **Data Engineering**: ETL pipeline design (AWS Data Engineering certification), data warehousing (Redshift, Databricks, Oracle), and cloud-based workflows on **AWS (S3, Lambda, EC2)**.  
- **Visualization**: Power BI, Tableau, and matplotlib/seaborn, used to deliver actionable insights across technical and non-technical audiences.  
- **Machine Learning**: Regression, clustering, time-series forecasting, and computer vision models (OpenCV, PyTorch, TensorFlow/Keras).  
- **Governance & Security**: Data access control, anonymization, GDPR-compliant workflows, and secure handling of sensitive humanitarian data.  
- **DevOps & Architecture**: Git, Docker, and scalable deployment across AWS-based stacks and hybrid infrastructure.

I pride myself on translating messy, complex datasets into clean, scalable, and insightful decision systems.


Languages
====
![image](https://github.com/user-attachments/assets/9030a3b1-024d-42fc-898f-ac549a35d416){: .align-right width="200"}  
My multicultural career path has helped me build strong communication skills in several languages:  
- **English** – Full professional proficiency  
- **Spanish** – Full professional proficiency  
- **Czech** – Full professional proficiency  
- **Serbian** – Native  
- **Russian** – Working proficiency  
- **German** – B1 level

These language skills have been instrumental in navigating international teams, field operations, and cross-border collaborations—from leading data workshops in Damascus to co-designing systems in Geneva and Caracas.

---

